# -*- coding: utf-8 -*-
"""nlp_model_bert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Gs24S42GmwBLO34PvZXdmUbesetYeKF

# Import necessary libraries and datasets
"""

!pip install evaluate

!pip install seqeval

import re
import ast
import random
import pandas as pd
import numpy as np
from typing import List, Tuple, Dict

import torch
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report # Import classification_report

from transformers import (
    AutoTokenizer,
    AutoModelForTokenClassification,
    TrainingArguments,
    Trainer,
    DataCollatorForTokenClassification,
)
from datasets import Dataset
from evaluate import load as load_metric

"""# Basic configurations

"""

MODEL_NAME = "bert-base-uncased"
MAX_LENGTH = 256
BATCH_SIZE = 8
EPOCHS = 3
LR = 5e-5
SEED = 42

# Define which columns map to which entity types
LABEL_ENTITIES = {
    "MATERIAL": "material",
    "CERTIFICATION": "certifications",
    "BRAND": "brand",
    "BADGE": "badges",
}

"""# Data Cleaning"""

def normalize_list_field(value):
    """Convert comma-separated or list-like strings into a clean lowercase list."""
    if pd.isna(value):
        return []
    if isinstance(value, list):
        items = value
    else:
        s = str(value).strip()
        try:
            # Try parsing Python-style list string
            if s.startswith("[") and s.endswith("]"):
                items = list(ast.literal_eval(s))
            else:
                items = re.split(r"[;,/|]", s)
        except Exception:
            items = re.split(r"[;,/|]", s)
    return [i.strip().lower() for i in items if i.strip()]

def find_spans(text, values, entity_type):
    """Find exact string matches for values in text (case-insensitive)."""
    spans = []
    lower_text = text.lower()
    for val in values:
        pattern = re.escape(val)
        for m in re.finditer(pattern, lower_text):
            start, end = m.start(), m.end()
            spans.append((start, end, entity_type))
    return spans

def extract_entities(row):
    """Generate entity spans from each row of the dataset."""
    text = str(row["raw_text"])
    spans = []
    for ent_label, col in LABEL_ENTITIES.items():
        vals = normalize_list_field(row.get(col))
        spans += find_spans(text, vals, ent_label)
    return sorted(spans, key=lambda x: x[0])

"""# Tokenization and Label"""

def build_label_list():
    entities = list(LABEL_ENTITIES.keys())
    labels = ["O"]
    for e in entities:
        labels.append("B-" + e)
        labels.append("I-" + e)
    return labels

def align_labels_with_tokens(example, tokenizer, label_to_id):
    """Align BIO labels with BERT tokens using offset mapping."""
    text = example["raw_text"]
    spans = extract_entities(example)

    tokenized = tokenizer(
        text,
        truncation=True,
        max_length=MAX_LENGTH,
        return_offsets_mapping=True,
    )

    labels = []
    for offset in tokenized["offset_mapping"]:
        start, end = offset
        if start == end:  # Special tokens
            labels.append(-100)
            continue

        assigned = "O"
        for s, e, lbl in spans:
            if s <= start < e or s < end <= e:
                assigned = "B-" + lbl if start == s else "I-" + lbl
                break
        labels.append(label_to_id[assigned])

    tokenized["labels"] = labels
    return tokenized

"""# Evaluation"""

def compute_metrics(eval_pred):
    metric = load_metric("seqeval")
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=2)

    true_predictions = [
        [id_to_label[p] for (p, l) in zip(pred, lab) if l != -100]
        for pred, lab in zip(predictions, labels)
    ]
    true_labels = [
        [id_to_label[l] for (p, l) in zip(pred, lab) if l != -100]
        for pred, lab in zip(predictions, labels)
    ]

    results = metric.compute(predictions=true_predictions, references=true_labels)
    return {
        "precision": results["overall_precision"],
        "recall": results["overall_recall"],
        "f1": results["overall_f1"],
        "accuracy": results["overall_accuracy"],
    }

"""# Main function(defining functions)"""

def load_and_prepare_data(path):
    df = pd.read_csv(path)
    df.dropna(subset=["raw_text"], inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df

def create_label_mapping(df):
    unique_labels = ["O", "MATERIAL", "CERTIFICATION", "BRAND", "BADGE"]
    label2id = {label: idx for idx, label in enumerate(unique_labels)}
    id2label = {idx: label for label, idx in label2id.items()}
    return label2id, id2label

def convert_to_ner_format(df):
    data = []
    for _, row in df.iterrows():
        text = row["raw_text"]
        entities = []

        def add_entity(value, label):
            if pd.notna(value):
                start = text.lower().find(str(value).lower())
                if start != -1:
                    entities.append((start, start + len(value), label))

        add_entity(row.get("material"), "MATERIAL")
        add_entity(row.get("certifications"), "CERTIFICATION")
        add_entity(row.get("brand"), "BRAND")
        add_entity(row.get("badges"), "BADGE")

        data.append({"text": text, "entities": entities})
    return data

def tokenize_and_align_labels(data, tokenizer, label2id):
    tokenized_inputs = tokenizer(
        [item["text"] for item in data],
        truncation=True,
        padding=True,
        max_length=256,
        return_offsets_mapping=True,
        is_split_into_words=False
    )

    labels = []
    for i, offsets in enumerate(tokenized_inputs["offset_mapping"]):
        text_labels = ["O"] * len(offsets)
        entities = data[i]["entities"]
        for start, end, label in entities:
            for idx, (offset_start, offset_end) in enumerate(offsets):
                if offset_start >= start and offset_end <= end:
                    text_labels[idx] = label
        labels.append([label2id[label] for label in text_labels])

    tokenized_inputs["labels"] = labels
    tokenized_inputs.pop("offset_mapping")
    return tokenized_inputs

def prepare_datasets(tokenized_inputs):
    n = len(tokenized_inputs["input_ids"])
    split = int(0.8 * n)
    train_data = {k: v[:split] for k, v in tokenized_inputs.items()}
    test_data = {k: v[split:] for k, v in tokenized_inputs.items()}
    return Dataset.from_dict(train_data), Dataset.from_dict(test_data)

def load_model_and_train(train_dataset, test_dataset, label2id, id2label):
    model_name = "bert-base-uncased"
    model = AutoModelForTokenClassification.from_pretrained(
        model_name,
        num_labels=len(label2id),
        id2label=id2label,
        label2id=label2id
    )

    training_args = TrainingArguments(
        output_dir="./bert_ner_results",
        eval_strategy="epoch",
        learning_rate=5e-5,
        per_device_train_batch_size=8,
        num_train_epochs=3,
        weight_decay=0.01,
        report_to="none",  # prevents API callouts
        save_strategy="epoch",
        logging_dir="./logs",
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        tokenizer=tokenizer
    )

    trainer.train()
    return trainer, model

from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np

def evaluate_model(trainer, test_dataset, id2label):
    """
    Evaluate BERT NER model — returns Accuracy, Precision, Recall, F1.
    """
    preds = trainer.predict(test_dataset)
    preds_label_ids = np.argmax(preds.predictions, axis=2)

    # Convert label IDs → label names (ignore -100 padding)
    true_labels = [
        [id2label[l] for l in label_seq if l != -100]
        for label_seq in preds.label_ids
    ]
    pred_labels = [
        [id2label[p] for (p, l) in zip(pred_seq, label_seq) if l != -100]
        for pred_seq, label_seq in zip(preds_label_ids, preds.label_ids)
    ]

    # Compute main metrics using seqeval
    accuracy = accuracy_score(true_labels, pred_labels)
    precision = precision_score(true_labels, pred_labels)
    recall = recall_score(true_labels, pred_labels)
    f1 = f1_score(true_labels, pred_labels)

    print("\n=== MODEL PERFORMANCE ===")
    print(f"Accuracy : {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall   : {recall:.4f}")
    print(f"F1 Score : {f1:.4f}")

    return {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1": f1
    }

"""# Main Function(calling functions)"""

df = load_and_prepare_data("/content/sustainable_products_dataset_expanded.csv")

label2id, id2label = create_label_mapping(df)

data = convert_to_ner_format(df)

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
tokenized_inputs = tokenize_and_align_labels(data, tokenizer, label2id)

train_dataset, test_dataset = prepare_datasets(tokenized_inputs)

trainer, model = load_model_and_train(train_dataset, test_dataset, label2id, id2label)

evaluate_model(trainer, test_dataset, id2label)

"""# Test"""

from transformers import AutoTokenizer, AutoModelForTokenClassification
from transformers import pipeline
import glob
import os

# Find the latest checkpoint directory
output_dir = "./bert_ner_results"
all_checkpoints = glob.glob(os.path.join(output_dir, "checkpoint-*"))
if not all_checkpoints:
    raise FileNotFoundError(f"No checkpoints found in {output_dir}")

# Get the latest checkpoint directory
latest_checkpoint = max(all_checkpoints, key=os.path.getmtime)
print(f"Loading model from: {latest_checkpoint}")

# Load the fine-tuned model
tokenizer = AutoTokenizer.from_pretrained(latest_checkpoint)
model = AutoModelForTokenClassification.from_pretrained(latest_checkpoint)

# Create a pipeline for NER
ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")

# Test sentence (you can change this)
new_sentence = "this hoodie is made from recycled polyester and organic cotton, certified by peta approved vegan, offered by christy dawn."

# Run NER
entities = ner_pipeline(new_sentence.lower())

# Print entities like in your spaCy code
print("\nEntities in the sentence:")
for ent in entities:
    print(f"- {ent['word']} ({ent['entity_group']})")

"""# Create Structured Data from BERT Outputs"""

import pandas as pd

# Assuming your existing entity extraction logic is in a function called `get_entities(sentence)`
# (If it's not a function yet, we’ll wrap the part where entities are printed)

def extract_entities_to_dict(sentence):
    # Use the pre-trained ner_pipeline to get entities
    pipeline_entities = ner_pipeline(sentence.lower()) # Convert sentence to lowercase for consistency

    # Initialize lists to collect all entities of each type
    extracted_materials = []
    extracted_certifications = []
    extracted_brands = []
    extracted_badges = []

    for ent in pipeline_entities:
        label = ent['entity_group']
        word = ent['word']

        if label == 'MATERIAL':
            extracted_materials.append(word)
        elif label == 'CERTIFICATION':
            extracted_certifications.append(word)
        elif label == 'BRAND':
            extracted_brands.append(word)
        elif label == 'BADGE':
            extracted_badges.append(word)

    # Join collected entities into comma-separated strings, or None if no entities found
    material = ", ".join(extracted_materials) if extracted_materials else None
    certification = ", ".join(extracted_certifications) if extracted_certifications else None
    brand = ", ".join(extracted_brands) if extracted_brands else None
    badges = ", ".join(extracted_badges) if extracted_badges else None

    return {
        "description": sentence,
        "material": material,
        "certification": certification,
        "brand": brand,
        "badges": badges
    }

# Example usage: batch-process a few products
product_texts = [
    "Christy Dawn recycled cotton PETA-approved vegan dress",
    "H&M Conscious organic linen GOTS certified shirt",
    "Stella McCartney vegan leather bag with cruelty-free certification",
    "Patagonia recycled polyester jacket with Fair Trade label",
    "Reformation organic cotton floral summer top"
]

structured_data = [extract_entities_to_dict(text) for text in product_texts]
df = pd.DataFrame(structured_data)
df

"""# Generate Text Embeddings (Using Your Same BERT Model)"""

import torch
import numpy as np

def get_mean_embedding(sentences, tokenizer, model, device='cpu'):
    embeddings = []
    for sentence in sentences:
        inputs = tokenizer(sentence, return_tensors="pt", truncation=True, padding=True, max_length=128)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        with torch.no_grad():
            # Request hidden states by passing output_hidden_states=True
            outputs = model(**inputs, output_hidden_states=True)
            # The last hidden state is the last element in the hidden_states tuple
            last_hidden_state = outputs.hidden_states[-1]
            # Take the mean of the token embeddings for the sentence embedding
            mean_emb = last_hidden_state.mean(dim=1).cpu().numpy()
            embeddings.append(mean_emb[0])
    return np.array(embeddings)

# Generate embeddings for all product descriptions
df['embedding'] = list(get_mean_embedding(df['description'].tolist(), tokenizer, model))

"""# Compute Combined Similarity (Text + Metadata)"""

from sklearn.metrics.pairwise import cosine_similarity

def compute_similarity_matrix(df):
    # Text-based similarity
    text_sim = cosine_similarity(list(df['embedding']))

    # Metadata-based similarity
    meta_sim = np.zeros_like(text_sim)
    for i in range(len(df)):
        for j in range(len(df)):
            score = 0
            if df.loc[i, 'material'] and df.loc[j, 'material'] and df.loc[i, 'material'] == df.loc[j, 'material']:
                score += 1.0
            if df.loc[i, 'certification'] and df.loc[j, 'certification'] and df.loc[i, 'certification'] == df.loc[j, 'certification']:
                score += 1.0
            if df.loc[i, 'brand'] and df.loc[j, 'brand'] and df.loc[i, 'brand'] == df.loc[j, 'brand']:
                score += 0.5
            meta_sim[i][j] = score

    # Normalize metadata similarity
    meta_sim = meta_sim / meta_sim.max() if meta_sim.max() != 0 else meta_sim

    # Weighted combination
    combined_sim = 0.7 * text_sim + 0.3 * meta_sim
    return combined_sim

similarity_matrix = compute_similarity_matrix(df)

"""# Build Recommendation Function"""

def recommend_products(target_description, df, similarity_matrix, top_n=3):
    # Find index of the target product
    idx = df.index[df['description'] == target_description].tolist()
    if not idx:
        print("Product not found in dataset.")
        return
    idx = idx[0]

    # Get similarity scores
    scores = list(enumerate(similarity_matrix[idx]))
    scores = sorted(scores, key=lambda x: x[1], reverse=True)

    print(f"\nRecommendations for: \"{target_description}\"\n")
    recs = []
    for i, score in scores[1:top_n+1]:
        recs.append((df.loc[i, 'description'], round(score, 3)))
        print(f"- {df.loc[i, 'description']} (Score: {round(score, 3)})")
    return recs

# Example usage:
recommend_products("Christy Dawn recycled cotton PETA-approved vegan dress", df, similarity_matrix, top_n=3)

"""# Display All Recommendations in a Table"""

all_recs = []
for desc in df['description']:
    recs = recommend_products(desc, df, similarity_matrix, top_n=2)
    for rec, score in recs:
        all_recs.append({"base_product": desc, "recommended": rec, "score": score})

recommendations_df = pd.DataFrame(all_recs)
recommendations_df